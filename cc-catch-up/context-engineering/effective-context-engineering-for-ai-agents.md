# AIエージェントのための効果的なコンテキストエンジニアリング

**公開日:** 2025年9月29日

**原文:** https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents

---

## はじめに

コンテキストは、AIエージェントにとって重要かつ有限なリソースです。この記事では、AIエージェントを支えるコンテキストを効果的にキュレーションし、管理するための戦略を探ります。

数年間にわたってプロンプトエンジニアリングが応用AI分野の注目の的でしたが、新しい用語が注目を集めるようになりました：**コンテキストエンジニアリング**です。言語モデルを使った開発は、プロンプトに適切な言葉やフレーズを見つけることから、「どのようなコンテキスト構成がモデルの望ましい動作を生成する可能性が最も高いか？」という、より広い問いに答えることへと変化しています。

**コンテキスト**とは、大規模言語モデル（LLM）からサンプリングする際に含まれるトークンのセットを指します。目の前の**エンジニアリング**の問題は、望ましい結果を一貫して達成するために、LLMの固有の制約に対してこれらのトークンの有用性を最適化することです。LLMを効果的に扱うには、*コンテキストで考える*必要があります。つまり、任意の時点でLLMが利用できる全体的な状態と、その状態が生み出す可能性のある動作を考慮することです。

この記事では、コンテキストエンジニアリングという新しい技術を探求し、操作可能で効果的なエージェントを構築するための洗練されたメンタルモデルを提供します。

## コンテキストエンジニアリング vs. プロンプトエンジニアリング

Anthropicでは、コンテキストエンジニアリングをプロンプトエンジニアリングの自然な進化として捉えています。プロンプトエンジニアリングは、最適な結果を得るためにLLMの指示を書き、整理する方法を指します（概要と有用なプロンプトエンジニアリング戦略については、[私たちのドキュメント](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)を参照してください）。**コンテキストエンジニアリング**は、プロンプト以外に到達する可能性のある他の全ての情報を含め、LLM推論中に最適なトークンセット（情報）をキュレーションし、維持するための戦略のセットを指します。

LLMを使ったエンジニアリングの初期の頃は、日常的なチャットインタラクション以外のユースケースの大部分が、ワンショット分類やテキスト生成タスクに最適化されたプロンプトを必要としていたため、プロンプティングがAIエンジニアリング作業の最大の構成要素でした。この用語が示すように、プロンプトエンジニアリングの主な焦点は、効果的なプロンプト、特にシステムプロンプトを書く方法です。しかし、複数の推論ターンやより長い時間軸で動作する、より有能なエージェントのエンジニアリングに移行するにつれて、コンテキスト状態全体（システム指示、ツール、[Model Context Protocol](https://modelcontextprotocol.io/docs/getting-started/intro)（MCP）、外部データ、メッセージ履歴など）を管理するための戦略が必要になります。

ループで動作するエージェントは、次の推論ターンに関連する*可能性がある*データをますます多く生成し、この情報は周期的に洗練される必要があります。コンテキストエンジニアリングは、絶えず進化する可能な情報の宇宙から、限られたコンテキストウィンドウに何を入れるかをキュレーションする[芸術と科学](https://x.com/karpathy/status/1937902205765607626?lang=en)です。

![プロンプトエンジニアリング vs. コンテキストエンジニアリング](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffaa261102e46c7f090a2402a49000ffae18c5dd6-2292x1290.png&w=3840&q=75)

*プロンプトを書くという個別のタスクとは対照的に、コンテキストエンジニアリングは反復的であり、モデルに何を渡すかを決定するたびにキュレーションフェーズが発生します。*

## なぜコンテキストエンジニアリングが有能なエージェント構築に重要なのか

速度とますます大量のデータを管理する能力にもかかわらず、私たちは、LLMが人間のように、ある時点で焦点を失ったり混乱を経験したりすることを観察してきました。針を干し草の山から探すスタイルのベンチマークに関する研究では、[コンテキストロット](https://research.trychroma.com/context-rot)という概念が明らかになりました：コンテキストウィンドウ内のトークン数が増えるにつれて、モデルがそのコンテキストから情報を正確に想起する能力が低下します。

一部のモデルは他のモデルよりも緩やかな劣化を示しますが、この特性はすべてのモデルに現れます。したがって、コンテキストは限界効用が逓減する有限リソースとして扱わなければなりません。[限られたワーキングメモリ容量](https://journals.sagepub.com/doi/abs/10.1177/0963721409359277)を持つ人間のように、LLMは大量のコンテキストを解析する際に利用する「注意予算」を持っています。導入される新しいトークンごとに、この予算が一定量消費され、LLMが利用できるトークンを慎重にキュレーションする必要性が高まります。

この注意の希少性は、LLMのアーキテクチャの制約に起因します。LLMは[トランスフォーマーアーキテクチャ](https://arxiv.org/abs/1706.03762)に基づいており、これにより、すべてのトークンがコンテキスト全体にわたって[他のすべてのトークンに注意を向ける](https://huggingface.co/blog/Esmail-AGumaan/attention-is-all-you-need)ことができます。これにより、nトークンに対してn²のペアワイズ関係が生じます。

コンテキスト長が増加するにつれて、これらのペアワイズ関係を捉えるモデルの能力が薄く引き伸ばされ、コンテキストサイズと注意の焦点の間に自然な緊張が生まれます。さらに、モデルは、長いシーケンスよりも短いシーケンスが一般的により一般的である訓練データ分布から注意パターンを発達させます。これは、モデルがコンテキスト全体の依存関係に対する経験が少なく、専門化されたパラメータも少ないことを意味します。

[位置エンコーディング補間](https://arxiv.org/pdf/2306.15595)のような技術により、モデルは元々訓練されたより小さなコンテキストに適応させることで、より長いシーケンスを処理できますが、トークン位置の理解にいくらかの劣化が伴います。これらの要因により、ハードな崖ではなく、パフォーマンスの勾配が生まれます：モデルはより長いコンテキストでも高い能力を維持しますが、より短いコンテキストでのパフォーマンスと比較して、情報検索や長距離推論の精度が低下する可能性があります。

これらの現実は、思慮深いコンテキストエンジニアリングが有能なエージェントを構築するために不可欠であることを意味します。

## 効果的なコンテキストの構造

LLMが有限の注意予算によって制約されていることを考えると、*良い*コンテキストエンジニアリングとは、望ましい結果の可能性を最大化する*最小可能な*高シグナルトークンのセットを見つけることを意味します。この実践を実装することは言うは易く行うは難しですが、次のセクションでは、この指針がコンテキストのさまざまなコンポーネントにわたって実際に何を意味するかを概説します。

### システムプロンプト

**システムプロンプト**は、エージェントにとって*適切な高度*でアイデアを提示する、極めて明確でシンプルで直接的な言語を使用すべきです。適切な高度とは、2つの一般的な失敗モードの間のゴルディロックスゾーンです。一方の極端では、エンジニアが正確なエージェント的動作を引き出すために、プロンプトに複雑で脆弱なロジックをハードコーディングしているのを見ます。このアプローチは脆弱性を生み、時間の経過とともにメンテナンスの複雑さを増大させます。もう一方の極端では、エンジニアは時々、望ましい出力に対する具体的なシグナルを提供できない、または誤って共有コンテキストを前提とする、曖昧で高レベルのガイダンスを提供します。最適な高度はバランスを取ります：動作を効果的に導くのに十分具体的でありながら、モデルに動作を導く強力なヒューリスティックを提供するのに十分柔軟です。

![コンテキストエンジニアリングのプロセスにおけるシステムプロンプトの調整](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F0442fe138158e84ffce92bed1624dd09f37ac46f-2292x1288.png&w=3840&q=75)

*スペクトルの一端には、脆弱なif-elseハードコーディングされたプロンプトがあり、もう一端には、過度に一般的であるか、誤って共有コンテキストを前提とするプロンプトがあります。*

私たちは、プロンプトを異なるセクション（`<background_information>`、`<instructions>`、`## Tool guidance`、`## Output description`など）に整理し、XMLタグやMarkdownヘッダーのような技術を使用してこれらのセクションを区切ることをお勧めします。ただし、モデルがより有能になるにつれて、プロンプトの正確なフォーマットはおそらくそれほど重要ではなくなっています。

システムプロンプトの構造をどのように決定するにしても、期待される動作を完全に概説する最小限の情報セットを目指すべきです。（最小限は必ずしも短いという意味ではないことに注意してください。望ましい動作に従うことを保証するために、エージェントに前もって十分な情報を与える必要があります。）利用可能な最良のモデルで最小限のプロンプトをテストすることから始めて、タスクでどのように機能するかを確認し、初期テスト中に見つかった失敗モードに基づいて、明確な指示と例を追加してパフォーマンスを向上させるのがベストです。

### ツール

**ツール**は、エージェントが環境で動作し、作業中に新しい追加のコンテキストを引き込むことを可能にします。ツールはエージェントとその情報/アクション空間の間の契約を定義するため、ツールが効率性を促進することが非常に重要です。これは、トークン効率的な情報を返すことと、効率的なエージェント動作を奨励することの両方によって行われます。

[AIエージェントのためのツールを書く – AIエージェントとともに](https://www.anthropic.com/engineering/writing-tools-for-agents)では、LLMによって十分に理解され、機能の重複が最小限であるツールを構築することについて議論しました。よく設計されたコードベースの機能と同様に、ツールは自己完結型で、エラーに対して堅牢で、意図された使用に関して極めて明確であるべきです。入力パラメータも同様に、説明的で、曖昧さがなく、モデルの固有の強みに適合している必要があります。

私たちが見る最も一般的な失敗モードの1つは、過剰な機能をカバーしたり、どのツールを使用するかについての曖昧な決定点につながる肥大化したツールセットです。人間のエンジニアが特定の状況でどのツールを使用すべきか明確に言えない場合、AIエージェントがそれよりうまくやることは期待できません。後で説明するように、エージェントのための最小限の実行可能なツールセットをキュレーションすることは、長いインタラクションにわたってコンテキストのより信頼性の高いメンテナンスとプルーニングにもつながる可能性があります。

### 例の提供

例を提供すること、別名フューショットプロンプティングは、私たちが引き続き強く推奨する、よく知られたベストプラクティスです。しかし、チームは、LLMが特定のタスクのために従うべきすべての可能なルールを明確にしようとして、エッジケースのランドリーリストをプロンプトに詰め込むことがよくあります。私たちはこれを推奨しません。代わりに、エージェントの期待される動作を効果的に描写する、多様で標準的な例のセットをキュレーションすることをお勧めします。LLMにとって、例は「千の言葉に値する絵」です。

コンテキストのさまざまなコンポーネント（システムプロンプト、ツール、例、メッセージ履歴など）にわたる私たちの全体的なガイダンスは、思慮深く、コンテキストを有益かつ簡潔に保つことです。それでは、実行時にコンテキストを動的に取得することに飛び込みましょう。

## コンテキスト検索とエージェント的検索

[効果的なAIエージェントの構築](https://www.anthropic.com/research/building-effective-agents)では、LLMベースのワークフローとエージェントの違いを強調しました。その記事を書いて以来、私たちはエージェントの[シンプルな定義](https://simonwillison.net/2025/Sep/18/agents/)に引き寄せられてきました：LLMがループでツールを自律的に使用すること。

顧客と並んで作業する中で、私たちはこのシンプルなパラダイムに収束している分野を見てきました。基礎となるモデルがより有能になるにつれて、エージェントの自律性のレベルはスケールできます：よりスマートなモデルは、エージェントがニュアンスのある問題空間を独立してナビゲートし、エラーから回復することを可能にします。

私たちは今、エンジニアがエージェントのためのコンテキストを設計する方法についての考え方のシフトを見ています。今日、多くのAIネイティブアプリケーションは、エージェントが推論する重要なコンテキストを表面化するために、推論前の時間に何らかの形式の埋め込みベースの検索を採用しています。この分野がよりエージェント的なアプローチに移行するにつれて、これらの検索システムを「ジャストインタイム」コンテキスト戦略で強化するチームが増えています。

すべての関連データを事前に前処理するのではなく、「ジャストインタイム」アプローチで構築されたエージェントは、軽量な識別子（ファイルパス、保存されたクエリ、Webリンクなど）を維持し、これらの参照を使用して、ツールを使用して実行時にコンテキストにデータを動的にロードします。Anthropicのエージェント的コーディングソリューション[Claude Code](https://www.anthropic.com/claude-code)は、このアプローチを使用して、大規模データベース上で複雑なデータ分析を実行します。モデルは、ターゲットを絞ったクエリを書き、結果を保存し、headやtailのようなBashコマンドを活用して、完全なデータオブジェクトをコンテキストにロードすることなく大量のデータを分析できます。このアプローチは人間の認知を反映しています：私たちは一般的に情報のコーパス全体を記憶するのではなく、ファイルシステム、受信トレイ、ブックマークのような外部の組織化およびインデックス化システムを導入して、オンデマンドで関連情報を検索します。

ストレージ効率を超えて、これらの参照のメタデータは、明示的に提供されるか直感的であるかにかかわらず、動作を効率的に洗練するメカニズムを提供します。ファイルシステムで動作するエージェントにとって、`tests`フォルダー内の`test_utils.py`という名前のファイルの存在は、`src/core_logic/`に配置された同じ名前のファイルとは異なる目的を意味します。フォルダー階層、命名規則、タイムスタンプはすべて、人間とエージェントの両方が情報をどのように、いつ利用するかを理解するのに役立つ重要なシグナルを提供します。

エージェントがデータを自律的にナビゲートして取得できるようにすることは、プログレッシブディスクロージャー、つまり、エージェントが探索を通じて関連するコンテキストを段階的に発見できるようにすることも可能にします。各インタラクションは次の決定を通知するコンテキストを生み出します：ファイルサイズは複雑さを示唆し、命名規則は目的をほのめかし、タイムスタンプは関連性のプロキシになります。エージェントは、レイヤーごとに理解を組み立て、ワーキングメモリに必要なものだけを維持し、追加の永続性のためにノート取り戦略を活用できます。この自己管理型コンテキストウィンドウは、包括的だが潜在的に無関係な情報に溺れるのではなく、関連するサブセットに焦点を当て続けます。

もちろん、トレードオフがあります：実行時の探索は、事前計算されたデータを取得するよりも遅いです。それだけでなく、LLMが情報ランドスケープを効果的にナビゲートするための適切なツールとヒューリスティックを持つことを保証するために、意見のある思慮深いエンジニアリングが必要です。適切なガイダンスがなければ、エージェントは、ツールを誤用したり、行き止まりを追いかけたり、重要な情報を特定できなかったりすることで、コンテキストを無駄にする可能性があります。

特定の設定では、最も効果的なエージェントは、ハイブリッド戦略を採用し、速度のために一部のデータを事前に取得し、その裁量でさらなる自律的な探索を追求する場合があります。「適切な」自律性レベルの決定境界は、タスクに依存します。Claude Codeは、このハイブリッドモデルを採用するエージェントです：[CLAUDE.md](http://claude.md/)ファイルは事前にコンテキストに単純にドロップされ、globやgrepのようなプリミティブは、環境をナビゲートしてジャストインタイムでファイルを取得することを可能にし、古いインデックス化と複雑な構文ツリーの問題を効果的にバイパスします。

ハイブリッド戦略は、法律や金融業務のような、動的なコンテンツが少ないコンテキストにより適している可能性があります。モデルの能力が向上するにつれて、エージェント的設計は、人間のキュレーションをますます少なくして、インテリジェントなモデルがインテリジェントに行動できるようにする方向に傾くでしょう。この分野の急速な進歩のペースを考えると、「機能する最もシンプルなことをする」ことは、Claudeの上にエージェントを構築するチームにとって、おそらく最良のアドバイスであり続けるでしょう。

### 長期的タスクのためのコンテキストエンジニアリング

長期的タスクでは、トークン数がLLMのコンテキストウィンドウを超える一連のアクションにわたって、エージェントが一貫性、コンテキスト、目標指向の動作を維持する必要があります。大規模なコードベースの移行や包括的な研究プロジェクトのような、数十分から数時間にわたる連続作業にまたがるタスクの場合、エージェントはコンテキストウィンドウサイズの制限を回避するための特殊な技術を必要とします。

より大きなコンテキストウィンドウを待つことは明白な戦術のように見えるかもしれません。しかし、少なくとも最も強力なエージェントのパフォーマンスが望まれる状況では、当面の間、あらゆるサイズのコンテキストウィンドウがコンテキスト汚染と情報関連性の懸念の対象となる可能性が高いです。エージェントが拡張された時間軸にわたって効果的に機能できるようにするために、私たちはこれらのコンテキスト汚染の制約に直接対処するいくつかの技術を開発しました：圧縮、構造化されたノート取り、およびマルチエージェントアーキテクチャ。

#### 圧縮（Compaction）

圧縮は、コンテキストウィンドウの制限に近づいている会話を取り、その内容を要約し、要約で新しいコンテキストウィンドウを再開する実践です。圧縮は通常、より良い長期的な一貫性を推進するためのコンテキストエンジニアリングの最初のレバーとして機能します。その核心において、圧縮はコンテキストウィンドウの内容を高忠実度で蒸留し、エージェントが最小限のパフォーマンス低下で続行できるようにします。

たとえば、Claude Codeでは、メッセージ履歴をモデルに渡して、最も重要な詳細を要約および圧縮することで、これを実装しています。モデルは、アーキテクチャの決定、未解決のバグ、実装の詳細を保持しながら、冗長なツール出力やメッセージを破棄します。その後、エージェントは、この圧縮されたコンテキストと、最近アクセスされた5つのファイルで続行できます。ユーザーは、コンテキストウィンドウの制限を心配することなく、継続性を得ることができます。

圧縮の技術は、何を保持するかと何を破棄するかの選択にあります。過度に積極的な圧縮は、その重要性が後で明らかになる微妙だが重要なコンテキストの損失につながる可能性があります。圧縮システムを実装するエンジニアには、複雑なエージェントトレースで圧縮プロンプトを慎重に調整することをお勧めします。まず、圧縮プロンプトがトレースから関連する情報のすべての部分をキャプチャすることを保証するために、再現率を最大化することから始め、次に余分なコンテンツを排除することで精度を向上させるために反復します。

低くぶら下がっている余分なコンテンツの例は、ツールコールと結果をクリアすることです – ツールがメッセージ履歴の深部で呼び出されると、エージェントが生の結果を再度見る必要があるのはなぜですか？最も安全で軽いタッチの形式の圧縮の1つは、ツール結果のクリアであり、最近[Claude Developer Platformの機能](https://www.anthropic.com/news/context-management)としてローンチされました。

#### 構造化されたノート取り

構造化されたノート取り、またはエージェント的メモリは、エージェントがコンテキストウィンドウの外のメモリに永続化されたノートを定期的に書き込む技術です。これらのノートは、後でコンテキストウィンドウに引き戻されます。

この戦略は、最小限のオーバーヘッドで永続的なメモリを提供します。Claude Codeがto-doリストを作成したり、カスタムエージェントがNOTES.mdファイルを維持したりするように、このシンプルなパターンにより、エージェントは複雑なタスクにわたって進捗を追跡し、数十のツールコールにわたって失われる可能性のある重要なコンテキストと依存関係を維持できます。

[Claudeがポケモンをプレイ](https://www.twitch.tv/claudeplayspokemon)することは、メモリがコーディング以外のドメインでエージェントの能力をどのように変換するかを示しています。エージェントは、数千のゲームステップにわたって正確な集計を維持します。「過去1,234ステップの間、私はルート1でポケモンをトレーニングしており、ピカチュウは目標の10に向けて8レベルを獲得しました」のような目標を追跡します。メモリ構造についてのプロンプトなしで、探索された地域の地図を開発し、どの重要な成果がアンロックされたかを覚え、異なる対戦相手に対してどの攻撃が最もうまく機能するかを学ぶのに役立つ戦闘戦略の戦略的メモを維持します。

コンテキストリセット後、エージェントは自分自身のノートを読み、数時間にわたるトレーニングシーケンスやダンジョン探索を続けます。要約ステップにわたるこの一貫性は、LLMのコンテキストウィンドウだけにすべての情報を保持する場合には不可能な長期的戦略を可能にします。

私たちの[Sonnet 4.5ローンチ](https://www.anthropic.com/effective-context-engineering-for-ai-agents)の一環として、Claude Developer Platformでパブリックベータ版の[メモリツール](http://anthropic.com/news/context-management)をリリースしました。これにより、ファイルベースのシステムを通じてコンテキストウィンドウの外に情報を保存および参照することが容易になります。これにより、エージェントは時間の経過とともに知識ベースを構築し、セッション間でプロジェクトの状態を維持し、すべてをコンテキストに保持することなく以前の作業を参照できます。

#### サブエージェントアーキテクチャ

サブエージェントアーキテクチャは、コンテキスト制限を回避する別の方法を提供します。1つのエージェントがプロジェクト全体にわたって状態を維持しようとするのではなく、専門化されたサブエージェントは、クリーンなコンテキストウィンドウで焦点を絞ったタスクを処理できます。メインエージェントは高レベルの計画で調整し、サブエージェントは深い技術的作業を実行したり、ツールを使用して関連情報を見つけたりします。各サブエージェントは広範囲に探索し、数万トークン以上を使用する可能性がありますが、その作業の凝縮された蒸留された要約のみを返します（多くの場合1,000〜2,000トークン）。

このアプローチは、明確な関心の分離を達成します。詳細な検索コンテキストはサブエージェント内に隔離され、リードエージェントは結果の合成と分析に焦点を当てます。[私たちのマルチエージェント研究システムの構築方法](https://www.anthropic.com/engineering/multi-agent-research-system)で議論されたこのパターンは、複雑な研究タスクにおいて、シングルエージェントシステムよりも大幅な改善を示しました。

これらのアプローチの選択は、タスクの特性に依存します。たとえば：

- 圧縮は、広範なやり取りを必要とするタスクの会話の流れを維持します
- ノート取りは、明確なマイルストーンを持つ反復的開発に優れています
- マルチエージェントアーキテクチャは、並行探索が利益をもたらす複雑な研究と分析を処理します

モデルが改善し続けても、拡張されたインタラクションにわたって一貫性を維持するという課題は、より効果的なエージェントを構築する中心であり続けるでしょう。

## 結論

コンテキストエンジニアリングは、LLMを使った構築方法における根本的なシフトを表しています。モデルがより有能になるにつれて、課題は完璧なプロンプトを作成することだけではなく、各ステップでモデルの限られた注意予算にどの情報が入るかを思慮深くキュレーションすることです。長期的タスクのために圧縮を実装する場合でも、トークン効率的なツールを設計する場合でも、エージェントがジャストインタイムで環境を探索できるようにする場合でも、指針は同じままです：望ましい結果の可能性を最大化する最小の高シグナルトークンのセットを見つけること。

私たちが概説した技術は、モデルが改善するにつれて進化し続けるでしょう。私たちはすでに、よりスマートなモデルがより規範的でないエンジニアリングを必要とし、エージェントがより多くの自律性で動作できるようにすることを見ています。しかし、能力がスケールしても、コンテキストを貴重で有限なリソースとして扱うことは、信頼性の高い効果的なエージェントを構築する中心であり続けるでしょう。

今日、Claude Developer Platformでコンテキストエンジニアリングを始めて、私たちの[メモリとコンテキスト管理](https://github.com/anthropics/claude-cookbooks/blob/main/tool_use/memory_cookbook.ipynb)クックブックを通じて、役立つヒントとベストプラクティスにアクセスしてください。

## 謝辞

Anthropicの応用AIチームによって書かれました：Prithvi Rajasekaran、Ethan Dixon、Carly Ryan、Jeremy Hadfield、チームメンバーRafi Ayub、Hannah Moran、Cal Rueb、Connor Jenningsからの貢献がありました。Molly Vorwerck、Stuart Ritchie、Maggie Voのサポートに特別な感謝を捧げます。

---

## 翻訳者注

この記事は、AnthropicがAIエージェントのためのコンテキストエンジニアリングについて解説したものです。プロンプトエンジニアリングからコンテキストエンジニアリングへのシフトが進んでおり、LLMの限られた注意予算を効果的に管理することが、より有能なエージェントを構築する鍵となります。

### 主なポイント

1. **コンテキストは有限リソース**: LLMのコンテキストウィンドウは大きくなっていますが、注意の希薄化（context rot）により、コンテキストが増えるほど情報の想起能力が低下します。

2. **最小限かつ高シグナルなコンテキスト**: 望ましい結果を得るために、最小限の高品質な情報セットを維持することが重要です。

3. **ジャストインタイム検索**: 事前にすべてのデータをロードするのではなく、実行時に必要なデータを動的に取得する戦略が効果的です。

4. **長期タスクのための技術**:
   - **圧縮**: コンテキストウィンドウの内容を要約して新しいウィンドウで再開
   - **構造化されたノート取り**: コンテキスト外にメモリを永続化
   - **サブエージェントアーキテクチャ**: 専門化されたエージェントで複雑なタスクを分割

5. **適切な高度のプロンプト**: 過度に具体的すぎず、曖昧すぎない、バランスの取れた指示が重要です。

この記事は、AIエージェントを構築する際の実践的なガイドラインを提供しており、今後のエージェント開発において非常に参考になる内容です。
